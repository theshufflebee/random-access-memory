---
title: "DSGE Replication Tests"
output:
  pdf_document: 
    toc: true
    fig_caption: yes
    latex_engine: lualatex
header-includes:
  - \usepackage{amsmath}
---
\newpage




```{r library_setup, results=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
rm(list=ls())
require(tinytex) #LaTeX
require(ggplot2) #plots
require(AER) #NW formula
require(dplyr) #data management
require(lubridate) #data dates management
require(zoo) #for lagging
require(jtools) #tables
require(huxtable) #tables
require(readxl) #for reading excel data
require(R.matlab) #for loading matlab data
require(eurostat) #eurostat data
require(fredr) #fredr data
require(mFilter) #HP filter
require(knitr) #tables
require(kableExtra) #tables extra
require(purrr) #data?

getwd()
setwd("...") 

#api for data
fredr_set_key(Sys.getenv("FRED_API_KEY"))

#dates
start_date <- "1955-07-01"
end_date <- "1984-01-01"


```
# Data
```{r data call and merge}

# Series id and the respective data name
series_map <- list(
  "GNPC96"             = "output",
#   "GNP"                = "output",
#  "CORESTICKM159SFRBATL" = "prices",
  "GPDIC1"             = "investment",
  "PCEND"                = "cons_nondurables", # Fetch component 1
  "PCES"                 = "cons_services",
  "AWHMAN"     = "hours")

# Use API calls and merge data (quarterly)
data <- map_dfr(names(series_map), function(id) {
  fredr(series_id = id, 
        observation_start = as.Date(start_date), 
        observation_end = as.Date(end_date),
        frequency = "q",
        aggregation_method = "avg")   %>% 
    mutate(series_name = series_map[[id]]) }) %>%
  select(date, series_name, value) %>%    
  tidyr::pivot_wider(                     
    names_from = series_name, 
    values_from = value) %>%
  mutate(consumption = cons_nondurables + cons_services) %>% 
  select(-cons_nondurables, -cons_services) %>%
  mutate(productivity = output / hours)
rm(series_map)

```



```{r logged and detrendng}

# 1. Define a helper function to Log, Detrend, and Extract the Cycle
get_cyclical_component <- function(x, freq = 1600) {

    # Take the log
    log_x <- log(x)
    
    # Apply HP Filter
    hp_result <- hpfilter(log_x, freq = freq)
    
    # Return the cyclical component
    return(hp_result$cycle) }




data = na.omit(data)

# 2. Apply to data
cyclical_data <- data %>%
  mutate(across(
    .cols = where(is.numeric), 
    .fns = get_cyclical_component,
    .names = "{.col}"))

```

```{r stats}

# Computing SD and Correlation with output
summary_table <- map_dfr(names(cyclical_data)[names(cyclical_data) != "date"], function(col_name) {
  
  # Extract the specific series and the baseline output series
  series_cycle <- cyclical_data[[col_name]]
  output_cycle <- cyclical_data[["output"]]
  
  # Calculate Stats 
  sd_val <- sd(series_cycle, na.rm = TRUE) * 100
  cor_val <- cor(series_cycle, output_cycle, use = "complete.obs")
  
  tibble(
    Series = col_name,
    `Standard Deviation` = round(sd_val, 2),
    `Correlation with Output` = round(cor_val, 2))})

print(summary_table)

```


# Caluclate Utilitx Los

## Load Steady State Values
```{r load ss values}
library(readr)
library(stringr)

# List all CSV files in the 'model' folder, all of them start in the same way so we can loop over them
# These are from the Dynare code that uses octave to create them extracting steady state values
files <- list.files(path = "models", 
                    pattern = "steady_state_values_g_.*\\.csv", 
                    full.names = TRUE)

# Loop through and create a separate data frame for each
for (fl in files) {
  
  # Extract the specific g-part (money growth) to name the data frame
  df_name <- paste0("ss_", str_extract(fl, "g_\\d+_\\d+"))
  
  # Read the file and assign it to that name
  assign(df_name, read_csv(fl, show_col_types = FALSE))
  
  message(paste("Created data frame:", df_name))
}
```


## Build the full Dataframe
```{r build ss dataframe}
library(dplyr)
library(tidyr)
library(purrr)

# 1. Get the names of all the ss_g_ data frames you just created
ss_object_names <- ls(pattern = "^ss_g_")

# 2. Combine them into one long data frame
master_table <- ss_object_names %>%
  map_df(~ {
    # Get the actual data frame using its name
    df <- get(.x)
    # Add a column to identify which inflation rate this came from
    df %>% mutate(source_g = .x)
  })

# 3. Pivot the table so each variable (c, h, y, etc.) is a column for easier reading and later interpretation
consolidated_ss_table <- master_table %>%
  pivot_wider(names_from = Variable, values_from = Value) %>%
  
  # Clean up the name for better sorting
  mutate(g_val = as.numeric(gsub("_", ".", gsub("ss_g_", "", source_g)))) %>%
  arrange(g_val)

# 4. View the result
print(consolidated_ss_table)
```


## Set Up Utility Loss Function
```{r def function utility loss}
library(dplyr)
library(tidyr)

# Define Function to calculate delta C for each money growth
calculate_delta_C <- function(U_bar, C_star, H_star, B_val = B_val){
  return(exp(U_bar + (B_val * H_star)) - C_star)
}
```


## Calculate Utility Loss
```{r calculate utility loss}
B_val <- 2.86

U_bar_benchmark <- log(consolidated_ss_table$c[1]) - B_val * consolidated_ss_table$h[1]

# Use the above function to calculate losses for all money growth scenarios
utility_results <- consolidated_ss_table %>%
  mutate(
    delta_C = calculate_delta_C(U_bar = U_bar_benchmark, 
                                C_star = c, 
                                H_star = h, 
                                B_val = B_val),
    
    # Calculate loss as % of steady-state consumption
    loss_c_pct = (delta_C / c) * 100,
    
    # Calculate loss as % of steady-state output (GNP)
    loss_y_pct = (delta_C / y) * 100
  ) %>%
  mutate(across(c(loss_c_pct, loss_y_pct), ~round(.x, 3)))

print(utility_results %>% select(g_val, c, h, delta_C, loss_c_pct, loss_y_pct))
```


## Build the Table 
```{r build utility loss table}
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)

# Prepare and Transpose Data
latex_data <- utility_results %>%
  mutate(
    # Corrected function name to case_when
    inflation_label = case_when(
      g_val == 0.99  ~ "-4 Percent",
      g_val == 1.00  ~ "0.0 Percent",
      g_val == 1.024 ~ "10 Percent",
      g_val == 1.19  ~ "100 Percent",
      g_val == 1.41  ~ "400 Percent",
      TRUE           ~ as.character(g_val)
    )
  ) %>%
  # Selecting the Variables we need from the df to construct our table
  select(
    inflation_label,
    `$g =$` = g_val,
    Output = y,
    Consumption = c,
    Investment = x,
    `Capital Stock` = k,
    Hours = h,
    `$\\Delta C/C \\times 100$` = loss_c_pct,
    `$\\Delta C/Y \\times 100$` = loss_y_pct
  ) %>%
  
  # Transpose variables to rows and inflation rates to columns
  pivot_longer(cols = -inflation_label, names_to = "Variable", values_to = "Value") %>%
  pivot_wider(names_from = inflation_label, values_from = Value)

# Now Generate LaTeX Code
latex_output <- kable(latex_data, 
      format = "latex", 
      booktabs = TRUE, 
      escape = FALSE, # Allows LaTeX math like $\Delta$ to render
      digits = 3,
      align = "lccccc",
      caption = " Welfare Costs Associated with Different Annual Growth Rates of Money") %>%
  kable_styling(latex_options = c("hold_position")) %>%
  add_header_above(c(" " = 1, "Annual Inflation Rate" = 5)) %>%
  pack_rows("Steady State", 2, 6) %>%
  pack_rows("Welfare Costs", 7, 8)

# Print to console
cat(latex_output)

# Save to a .tex file
writeLines(latex_output, "Table2_CooleyHansen_Replication.tex")
```






